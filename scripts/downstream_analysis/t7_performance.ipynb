{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81bb88a4-1d49-4c8b-8246-217685670a58",
   "metadata": {},
   "source": [
    "# T7 read processing performance\n",
    "This notebook was used to determine the sensitivity and specificity of T7 read processing by Sheriff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f022c-8309-4b12-9ae5-987fe49dd94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60917fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pysam\n",
    "import glob\n",
    "import subprocess\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bfc9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate positive set BAM files for sensitivity\n",
    "def make_pos_set_bams(parent_dir, bam_file_pattern, bed_file, cell_barcode_csv, output_bam):\n",
    "    # Ensure the BAM file pattern ends with \"*.bam\" if not already specified\n",
    "    if not bam_file_pattern.endswith(\".bam\"):\n",
    "        bam_file_pattern += \"*.bam\"\n",
    "\n",
    "    # Read the BED file into a DataFrame\n",
    "    bed_df = pd.read_csv(bed_file, sep='\\t', header=None, names=['chrom', 'start', 'end', 'name', 'sample'])\n",
    "\n",
    "    # Read the cell barcodes from the CSV file into a set for fast lookup\n",
    "    cell_barcodes_df = pd.read_csv(cell_barcode_csv)\n",
    "    cell_barcodes = set(cell_barcodes_df.iloc[:, 0].str.strip())\n",
    "\n",
    "    # Create a temporary directory for intermediate BAM files\n",
    "    temp_output_dir = os.path.join(os.path.dirname(output_bam), \"temp_bam_files\")\n",
    "    os.makedirs(temp_output_dir, exist_ok=True)\n",
    "\n",
    "    temp_bam_files = []\n",
    "\n",
    "    # Iterate over each row in the BED DataFrame\n",
    "    for index, row in bed_df.iterrows():\n",
    "        chromosome_name = row['chrom']\n",
    "        subdir_chromosome_name = chromosome_name.replace('hg38_', '')  # Remove \"hg38_\" for subdirectory search\n",
    "        start_pos = row['start']\n",
    "        end_pos = row['end']\n",
    "        name = row['name']\n",
    "        sample_range = row['sample']\n",
    "\n",
    "        # Parse the sample range\n",
    "        sample_start, sample_end = sample_range.replace('samples_', '').split('_to_')\n",
    "        sample_ids = [str(i).zfill(2) for i in range(int(sample_start), int(sample_end) + 1)]\n",
    "\n",
    "        # Find BAM files matching the pattern in the chromosome subdirectory\n",
    "        input_bam_files = glob.glob(os.path.join(parent_dir, subdir_chromosome_name, bam_file_pattern))\n",
    "\n",
    "        if not input_bam_files:\n",
    "            print(f\"No BAM files found for chromosome subdirectory '{subdir_chromosome_name}' with pattern '{bam_file_pattern}'\")\n",
    "            continue\n",
    "\n",
    "        for input_bam in input_bam_files:\n",
    "            try:\n",
    "                # Extract the original BAM filename without extension\n",
    "                bam_prefix = os.path.splitext(os.path.basename(input_bam))[0]\n",
    "                \n",
    "                # Define the temporary output BAM file path\n",
    "                temp_output_bam = os.path.join(temp_output_dir, f\"{bam_prefix}_at_{name}.bam\")\n",
    "\n",
    "                # Open the input BAM file for reading\n",
    "                bamfile = pysam.AlignmentFile(input_bam, \"rb\")\n",
    "\n",
    "                # Create the temporary output BAM file for writing\n",
    "                with pysam.AlignmentFile(temp_output_bam, \"wb\", header=bamfile.header) as out_bamfile:\n",
    "                    # Iterate over reads in the specified region\n",
    "                    for read in bamfile.fetch(chromosome_name, start_pos, end_pos):\n",
    "                        # Check if the read has the cell barcode tag\n",
    "                        if read.has_tag(\"CB\"):\n",
    "                            # Extract the cell barcode\n",
    "                            cell_barcode = read.get_tag(\"CB\")\n",
    "                            # Split the cell barcode to get the sample ID\n",
    "                            sample_id = cell_barcode.split('_')[0]\n",
    "                            # Check if the sample ID is in the list of desired sample IDs\n",
    "                            if sample_id in sample_ids:\n",
    "                                # Further filter by checking the read name against the cell barcodes\n",
    "                                if read.query_name[:8] in cell_barcodes:\n",
    "                                    # Write the read to the temporary output BAM file\n",
    "                                    out_bamfile.write(read)\n",
    "\n",
    "                temp_bam_files.append(temp_output_bam)\n",
    "                # print(f\"Temp BAM file saved to: {temp_output_bam}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing BAM file '{input_bam}': {e}\")\n",
    "                continue\n",
    "\n",
    "    # Check if there are temporary BAM files to merge\n",
    "    if temp_bam_files:\n",
    "        try:\n",
    "            # Merge all temporary BAM files into a single output BAM file\n",
    "            pysam.merge(\"-f\", output_bam, *temp_bam_files)\n",
    "            # Index the output BAM file\n",
    "            pysam.index(output_bam)\n",
    "\n",
    "            print(f\"Merged BAM file saved to: {output_bam}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error merging BAM files: {e}\")\n",
    "    else:\n",
    "        print(\"No BAM files were found matching the given pattern. No output file was created.\")\n",
    "\n",
    "    # Clean up temporary BAM files\n",
    "    for temp_bam in temp_bam_files:\n",
    "        if os.path.exists(temp_bam):\n",
    "            try:\n",
    "                os.remove(temp_bam)\n",
    "            except Exception as e:\n",
    "                print(f\"Error removing temporary BAM file '{temp_bam}': {e}\")\n",
    "    try:\n",
    "        os.rmdir(temp_output_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"Error removing temporary directory '{temp_output_dir}': {e}\")\n",
    "\n",
    "# Example usage\n",
    "# parent_dir = \"/path/to/parent_input_directory\"\n",
    "# bam_file_pattern = \"pattern*.bam\"\n",
    "# bed_file = \"/path/to/regions.bed\"\n",
    "# output_bam = \"/path/to/output.bam\"\n",
    "# cell_barcode_txt = \"/path/to/cell_barcodes.txt\"\n",
    "# make_pos_set_bams(parent_dir, bam_file_pattern, bed_file, cell_barcode_csv, output_bam):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db0a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make positive set BAM files\n",
    "# Input directory containing BAM files\n",
    "input_dir = # OMITTED\n",
    "# BED file of 7 on-target edit sites and corresponding split-pipe edited sample ids, to make positive set\n",
    "on_target_bed = # OMITTED\n",
    "# Input \"species_read_counts.csv\" file from Split-pipe output\n",
    "cell_bc_csv = # OMITTED\n",
    "# Output directory\n",
    "output_dir = # OMITTED\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "make_pos_set_bams(input_dir, 't7_barcoded_only.bam', on_target_bed, cell_bc_csv, output_dir+'t7_barcoded_only_pos.bam')\n",
    "make_pos_set_bams(input_dir, 't7_filt.bam', on_target_bed, cell_bc_csv, output_dir+'t7_filt_pos.bam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dbe5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter BAM files by list of sample ids\n",
    "def filter_bam_by_sample(input_bam, output_bam, sample_ids):\n",
    "    \"\"\"\n",
    "    Filters a BAM file based on sample IDs extracted from cell barcode tags and writes the output to a specified directory.\n",
    "    Additionally, indexes the output BAM file using pysam.\n",
    "    \n",
    "    Parameters:\n",
    "        input_bam (str): Path to the input BAM file.\n",
    "        output_bam (str): Path to the output BAM file.\n",
    "        sample_ids (list of str): List of sample IDs to filter for (e.g., ['01', '02']).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct the output BAM filename\n",
    "    input_filename = os.path.basename(input_bam)\n",
    "    base_name = os.path.splitext(input_filename)[0]\n",
    "    \n",
    "    # Open the input BAM file\n",
    "    with pysam.AlignmentFile(input_bam, \"rb\") as bamfile:\n",
    "        # Open the output BAM file\n",
    "        with pysam.AlignmentFile(output_bam, \"wb\", header=bamfile.header) as outfile:\n",
    "            # Iterate through each read in the BAM file\n",
    "            for read in bamfile:\n",
    "                # Check if the read has the cell barcode tag\n",
    "                if read.has_tag(\"CB\"):\n",
    "                    # Extract the cell barcode\n",
    "                    cell_barcode = read.get_tag(\"CB\")\n",
    "                    # Split the cell barcode to get the sample ID\n",
    "                    sample_id = cell_barcode.split('_')[0]\n",
    "                    # Check if the sample ID is in the list of desired sample IDs\n",
    "                    if sample_id in sample_ids:\n",
    "                        # Write the read to the output BAM file\n",
    "                        outfile.write(read)\n",
    "\n",
    "    # Index the output BAM file\n",
    "    pysam.index(output_bam)\n",
    "\n",
    "    print(f\"Filtered BAM file saved to: {output_bam}\")\n",
    "\n",
    "# Example usage\n",
    "# input_bam = \"path/to/input.bam\"\n",
    "# output_dir = \"path/to/output/directory\"\n",
    "# sample_ids = [\"01\", \"02\"]  # Replace with the desired sample IDs\n",
    "# filter_bam_by_sample(input_bam, output_bam, sample_ids):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5559fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to downsample BAM files\n",
    "def downsample_whitelist_bam(input_bam, output_bam, fraction=0.01, cell_barcode_csv=None, threads=8):\n",
    "    \"\"\"\n",
    "    Downsample a BAM file using samtools view -s and filter by cell barcodes.\n",
    "\n",
    "    Parameters:\n",
    "    input_bam (str): Path to the input BAM file.\n",
    "    output_bam (str): Path to the output BAM file.\n",
    "    fraction (float): Fraction of reads to keep (default is 0.01).\n",
    "    cell_barcode_csv (str): Path to the CSV file containing cell barcodes. If provided, the downsampled BAM will be filtered based on these barcodes.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Downsample the BAM file\n",
    "        print(f\"Starting downsampling: {input_bam}\")\n",
    "        print(f\"Downsampling fraction: {fraction}\")\n",
    "        command = [\"samtools\", \"view\", \"-@\", str(threads), \"-s\", str(fraction), \"-o\", output_bam, input_bam]\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Downsampled BAM saved to: {output_bam}\")\n",
    "\n",
    "        # Index downsampled BAM file\n",
    "        try:\n",
    "            pysam.index(output_bam)\n",
    "            print(f\"Index generated.\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error indexing whitelisted BAM file: {e}\")\n",
    "\n",
    "        # Step 2: Filter the downsampled BAM file if a barcode CSV is provided\n",
    "        if cell_barcode_csv:\n",
    "            # Read the cell barcodes from the CSV file\n",
    "            barcodes = pd.read_csv(cell_barcode_csv, header=0).iloc[:, 0].astype(str).str[:8].tolist()\n",
    "            barcodes_set = set(barcodes)\n",
    "\n",
    "            # Create the filtered BAM file name\n",
    "            filtered_bam = output_bam.replace(\".bam\", \"_white.bam\")\n",
    "\n",
    "            # Open the downsampled BAM file and create a new BAM file for filtered output\n",
    "            with pysam.AlignmentFile(output_bam, \"rb\") as bam_in, \\\n",
    "                 pysam.AlignmentFile(filtered_bam, \"wb\", header=bam_in.header) as bam_out:\n",
    "                \n",
    "                for read in bam_in:\n",
    "                    # Check if the read name's first 8 characters are in the barcodes set\n",
    "                    if read.query_name[:8] in barcodes_set:\n",
    "                        bam_out.write(read)\n",
    "            print(f\"Filtered BAM saved to: {filtered_bam}\")\n",
    "\n",
    "            # Index whitelisted BAM file\n",
    "            try:\n",
    "                pysam.index(filtered_bam)\n",
    "                print(f\"Index generated.\")\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"Error indexing whitelisted BAM file: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"No barcode CSV provided; skipping filtering step.\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred while running samtools: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "# downsample_whitelist_bam(\"input.bam\", \"output.bam\", 0.01, \"barcodes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c4e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for QC of downsampling\n",
    "def run_idxstats_command(bam_file):\n",
    "    command = f\"samtools idxstats '{bam_file}' | awk '{{sum += $3}} END {{print sum}}'\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    \n",
    "    return int(result.stdout.strip())\n",
    "\n",
    "def calc_bam_frac(frac_bam, full_bam):\n",
    "    count_frac = run_idxstats_command(frac_bam)\n",
    "    count_full = run_idxstats_command(full_bam)\n",
    "    fraction = count_frac / count_full\n",
    "    print(f'Read proportion: {fraction:.4f}')\n",
    "\n",
    "# Example usage\n",
    "# bam = \"path/to/original.bam\"\n",
    "# downsampled_bam = \"path/to/downsampled.bam\"\n",
    "# calc_bam_frac(bam, downsampled_bam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661ac6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare downsampled, cell-whitelisted BAM files for negative set generation\n",
    "input_dir = # OMITTED\n",
    "output_dir = # OMITTED\n",
    "\n",
    "downsample_whitelist_bam(\n",
    "    input_dir+'t7_barcoded_only.bam', output_dir't7_barcoded_only_down.bam', 0.01, cell_bc_csv\n",
    ")\n",
    "\n",
    "# Verify downsampling\n",
    "calc_bam_frac(\n",
    "    input_dir+'t7_barcoded_only.bam', output_dir't7_barcoded_only_down.bam'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8634fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make negative set BAM files\n",
    "input_dir =  = # OMITTED\n",
    "output_dir = # OMITTED\n",
    "no_edit_ids = ['01', '02']\n",
    "\n",
    "filter_bam_by_sample(\n",
    "    output_dir't7_barcoded_only_down.bam', output_dir+'t7_barcoded_only_neg.bam', no_edit_ids\n",
    ")\n",
    "filter_bam_by_sample(\n",
    "        output_dir't7_filt_down.bam', output_dir+'t7_filt_neg.bam', no_edit_ids\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37fee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to calculate sensitivity per sample replicate\n",
    "def count_by_idxstats(bam_file):\n",
    "    command = f\"samtools idxstats '{bam_file}' | awk '{{sum += $3}} END {{print sum}}'\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    return int(result.stdout.strip())\n",
    "\n",
    "def calc_sens(true_pos_bam, false_pos_bam):\n",
    "    tp_count = count_by_idxstats(true_pos_bam)\n",
    "    fp_count = count_by_idxstats(false_pos_bam)\n",
    "    sensitivity = tp_count / (tp_count + fp_count) * 100\n",
    "\n",
    "    sens_df = pd.DataFrame({\n",
    "    'true_pos': [tp_count],\n",
    "    'false_pos': [fp_count],\n",
    "    'sensitivity': [sensitivity]\n",
    "    })\n",
    "    \n",
    "    return sens_df\n",
    "\n",
    "def calc_spec(true_neg_bam, false_neg_bam):\n",
    "    tn_count = count_by_idxstats(true_neg_bam)\n",
    "    fn_count = count_by_idxstats(false_neg_bam)\n",
    "    specificity = tn_count / (tn_count + fn_count) * 100\n",
    "\n",
    "    spec_df = pd.DataFrame({\n",
    "    'true_neg': [tn_count],\n",
    "    'false_neg': [fn_count],\n",
    "    'specificity': [specificity]\n",
    "    })\n",
    "    \n",
    "    return spec_df\n",
    "\n",
    "def calc_performance_by_rep(true_bam, false_bam, sample_ids, test, output_dir):\n",
    "\n",
    "    print(f'Calculating: {test}...')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    true_bam_base = os.path.basename(true_bam)\n",
    "    false_bam_base = os.path.basename(false_bam)\n",
    "\n",
    "    dfs = []\n",
    "    \n",
    "    for id in sample_ids:\n",
    "        true_bam_id = os.path.join(output_dir, true_bam_base.replace('.bam', f'_{id}.bam'))\n",
    "        false_bam_id = os.path.join(output_dir, false_bam_base.replace('.bam', f'_{id}.bam'))\n",
    "\n",
    "        filter_bam_by_sample(true_bam, true_bam_id, id)\n",
    "        filter_bam_by_sample(false_bam, false_bam_id, id)\n",
    "\n",
    "        if test == 'sensitivity':\n",
    "            df = calc_sens(true_bam_id, false_bam_id)\n",
    "        if test == 'specificity':\n",
    "            df = calc_spec(true_bam_id, false_bam_id)\n",
    "\n",
    "        df.insert(0, 'sample_id', id)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    concat_df = pd.concat(dfs, ignore_index=True)\n",
    "    print('Done.')\n",
    "\n",
    "    return concat_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e3634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity in 10 edited sample IDs\n",
    "input_dir = # OMITTED\n",
    "output_dir = # OMITTED\n",
    "sample_ids = [\n",
    "    '03', '04', '05', '06', '07',\n",
    "    '08', '09' ,'10' ,'11', '12'\n",
    "]\n",
    "\n",
    "sens_rep_df = calc_performance_by_rep(\n",
    "    input_dir+'t7_only_pos.bam', input_dir+'t7_filt_pos.bam', sample_ids, 'sensitivity', output_dir\n",
    ")\n",
    "sens_rep_df.insert(0, 'version', 'v10')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4338ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sensitivity\n",
    "_ = plt.figure(figsize=(3, 4), layout=\"constrained\")\n",
    "bar_sens_rep = sns.barplot(\n",
    "    data=sens_rep_df, x='version', y='sensitivity', hue='version',\n",
    "    errorbar=None, estimator=np.mean\n",
    ")\n",
    "_ = sns.stripplot(\n",
    "    data=sens_rep_df, x='version', y='sensitivity', color='#000000', dodge=True, s=3\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "_ = plt.title('Sensitivity')\n",
    "_ = plt.xlabel('T7 processing version')\n",
    "_ = plt.ylabel('Percent')\n",
    "\n",
    "# Add labels above each bar\n",
    "for p in bar_sens_rep.patches:\n",
    "    bar_height = p.get_height()\n",
    "    _ = bar_sens_rep.annotate(\n",
    "        f'{bar_height:.0f}', \n",
    "        (p.get_x() + p.get_width() / 2., bar_height / 2), \n",
    "        ha='center', va='center', color='black', fontsize=10\n",
    "    )\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea41fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38a59c90",
   "metadata": {},
   "source": [
    "## Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c31e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specificity in each of two unedited sample replicates\n",
    "input_dir = # OMITTED\n",
    "output_dir = # OMITTED\n",
    "sample_ids = ['01', '02']\n",
    "\n",
    "spec_rep_df = calc_performance_by_rep(\n",
    "    input_dir+'t7_filt_neg.bam', input_dir+'t7_only_neg.bam', sample_ids, 'specificity', output_dir\n",
    ")\n",
    "spec_rep_df.insert(0, 'version', 'v10')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd1914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pot specificity\n",
    "np.random.seed(7)\n",
    "\n",
    "_ = plt.figure(figsize=(3, 4), layout=\"constrained\")\n",
    "bar_spec_rep = sns.barplot(\n",
    "    data=spec_rep_df, x='version', y='specificity', hue='version',\n",
    "    errorbar=None, estimator=np.mean\n",
    ")\n",
    "_ = sns.stripplot(\n",
    "    data=spec_rep_df, x='version', y='specificity', color='#000000', dodge=True, s=3\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "_ = plt.title('Specificity')\n",
    "_ = plt.xlabel('T7 processing version')\n",
    "_ = plt.ylabel('Percent')\n",
    "\n",
    "# Add labels above each bar\n",
    "for p in bar_spec_rep.patches:\n",
    "    bar_height = p.get_height()\n",
    "    _ = bar_spec_rep.annotate(\n",
    "        f'{bar_height:.2f}', \n",
    "        (p.get_x() + p.get_width() / 2., bar_height / 2), \n",
    "        ha='center', va='center', color='black', fontsize=10\n",
    "    )\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c1e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25b54a6c",
   "metadata": {},
   "source": [
    "## False discovery rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af15e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter BAM files for whitelisted cell barcodes\n",
    "def whitelist_bam(input_bam, output_dir, cell_barcode_csv=None, threads=16):\n",
    "    \"\"\"\n",
    "    Downsample a BAM file using samtools view -s and filter by cell barcodes.\n",
    "\n",
    "    Parameters:\n",
    "    input_bam (str): Path to the input BAM file.\n",
    "    output_bam (str): Path to the output BAM file.\n",
    "    cell_barcode_csv (str): Path to the CSV file containing cell barcodes. If provided, the downsampled BAM will be filtered based on these barcodes.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if cell_barcode_csv:\n",
    "            # Read the cell barcodes from the CSV file\n",
    "            barcodes = pd.read_csv(cell_barcode_csv, header=0).iloc[:, 0].astype(str).str[:8].tolist()\n",
    "            barcodes_set = set(barcodes)\n",
    "\n",
    "            # Create the filtered BAM file name\n",
    "            white_bam = os.path.join(output_dir, os.path.basename(input_bam).replace(\".bam\", \"_white.bam\"))\n",
    "\n",
    "            # Open the downsampled BAM file and create a new BAM file for filtered output\n",
    "            with pysam.AlignmentFile(input_bam, \"rb\") as bam_in, \\\n",
    "                 pysam.AlignmentFile(white_bam, \"wb\", header=bam_in.header) as bam_out:\n",
    "                \n",
    "                for read in bam_in:\n",
    "                    # Check if the read name's first 8 characters are in the barcodes set\n",
    "                    if read.query_name[:8] in barcodes_set:\n",
    "                        bam_out.write(read)\n",
    "            print(f\"Whitelisted BAM saved to: {white_bam}\")\n",
    "\n",
    "            # Index whitelisted BAM file\n",
    "            try:\n",
    "                pysam.index(white_bam)\n",
    "                print(f\"Index generated.\")\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"Error indexing whitelisted BAM file: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"No barcode CSV provided; skipping filtering step.\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred while running samtools: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "# whitelist_bam(input_bam, output_dir, cell_barcode_csv=None, threads=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282a9e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whitelist BAM files (without downsampling)\n",
    "input_dir = # OMITTED\n",
    "cell_bc_csv = # OMITTED\n",
    "\n",
    "# whitelist_bam(input_dir+'t7_only.bam', output_dir, cell_bc_csv, threads=16)\n",
    "whitelist_bam(input_dir+'t7_barcoded_only.bam', output_dir, cell_bc_csv, threads=16)\n",
    "\n",
    "# filter whitelisted BAM files for unedited sample reads\n",
    "input_dir = # OMITTED\n",
    "output_dir = # OMITTED\n",
    "no_edit_ids = ['01', '02']\n",
    "\n",
    "# filter_bam_by_sample(input_dir+'t7_only_white.bam', output_dir+'t7_only_neg.bam', no_edit_ids)\n",
    "filter_bam_by_sample(input_dir+'t7_barcoded_only_white.bam', output_dir+'t7_barcoded_only_neg.bam', no_edit_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6cc755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to calculate FDR per sample replicate\n",
    "def count_by_idxstats(bam_file):\n",
    "        command = f\"samtools idxstats '{bam_file}' | awk '{{sum += $3}} END {{print sum}}'\"\n",
    "        result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "        return int(result.stdout.strip())\n",
    "\n",
    "def calc_fdr(false_pos_bam, total_pos_bam):\n",
    "    fp_count = count_by_idxstats(false_pos_bam)\n",
    "    totp_count = count_by_idxstats(total_pos_bam) \n",
    "    fdr = fp_count / totp_count * 100\n",
    "\n",
    "    fdr_df = pd.DataFrame({\n",
    "    'false_pos': [fp_count],\n",
    "    'total_pos': [totp_count],\n",
    "    'fdr': [fdr]\n",
    "    })\n",
    "    \n",
    "    return fdr_df\n",
    "\n",
    "def calc_fdr_by_rep(false_bam, total_bam, neg_sample_ids, output_dir):\n",
    "\n",
    "    print(f'Calculating FDR by replicate...')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    false_bam_base = os.path.basename(false_bam)\n",
    "    tot_bam_base = os.path.basename(total_bam)\n",
    "\n",
    "    dfs = []\n",
    "    \n",
    "    for id in neg_sample_ids:\n",
    "        false_bam_id = os.path.join(output_dir, false_bam_base.replace('.bam', f'_{id}.bam'))\n",
    "        tot_bam_id = os.path.join(output_dir, tot_bam_base.replace('.bam', f'_for_{id}.bam'))\n",
    "\n",
    "        if id == '01':\n",
    "            tot_ids = ['01', '03', '05', '07', '09', '11']\n",
    "        if id == '02':\n",
    "            tot_ids = ['02', '04', '06', '08', '10', '12']\n",
    "        \n",
    "        filter_bam_by_sample(false_bam, false_bam_id, id)\n",
    "        filter_bam_by_sample(total_bam, tot_bam_id, tot_ids)\n",
    "        \n",
    "        df = calc_fdr(false_bam_id, tot_bam_id)\n",
    "\n",
    "        df.insert(0, 'sample_id', id)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    concat_df = pd.concat(dfs, ignore_index=True)\n",
    "    print('Done.')\n",
    "\n",
    "    return concat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c021ad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate FDR\n",
    "input_dir = # OMITTED\n",
    "output_dir = # OMITTED\n",
    "no_edit_ids = ['01', '02']\n",
    "\n",
    "fdr_rep_df = calc_fdr_by_rep(\n",
    "    input_dir+'t7_barcoded_only_neg.bam', input_dir+'t7_barcoded_only_white.bam', no_edit_ids, output_dir\n",
    ")\n",
    "fdr_rep_df.insert(0, 'version', 'v10')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67631bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot FDR\n",
    "np.random.seed(7)\n",
    "\n",
    "_ = plt.figure(figsize=(3, 4), layout=\"constrained\")\n",
    "bar_fdr_rep = sns.barplot(\n",
    "    data=fdr_rep_df, x='version', y='fdr', hue='version',\n",
    "    errorbar=None, estimator=np.mean\n",
    ")\n",
    "_ = sns.stripplot(\n",
    "    data=fdr_rep_df, x='version', y='fdr', color='#000000', dodge=True, s=3\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "_ = plt.title('FDR')\n",
    "_ = plt.xlabel('T7 processing version')\n",
    "_ = plt.ylabel('Percent')\n",
    "_ = plt.ylim(0, 100)\n",
    "\n",
    "# Add labels above each bar\n",
    "for p in bar_fdr_rep.patches:\n",
    "    bar_height = p.get_height()\n",
    "    _ = bar_fdr_rep.annotate(\n",
    "        f'{bar_height:.1f}', \n",
    "        (p.get_x() + p.get_width() / 2., bar_height + 8), \n",
    "        ha='center', va='center', color='black', fontsize=10\n",
    "    )\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981fb350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write performance results to pandas Parquet files\n",
    "output_dir = # OMITTED\n",
    "sens_rep_df.to_parquet(output_dir+'sensitivity.pq')\n",
    "spec_rep_df.to_parquet(output_dir+'specificity.pq')\n",
    "fdr_rep_df.to_parquet(output_dir+'fdr.pq')\n",
    "\n",
    "# Write performance results to TSV files\n",
    "sens_rep_df.to_csv(output_dir+'sensitivity.tsv', sep='\\t')\n",
    "spec_rep_df.to_csv(output_dir+'specificity.tsv', sep='\\t')\n",
    "fdr_rep_df.to_csv(output_dir+'fdr.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1d996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:superbpy]",
   "language": "python",
   "name": "conda-env-superbpy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
